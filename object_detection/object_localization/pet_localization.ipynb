{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pot_location.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "source": [
        "# Per Localization\n",
        "Datset used: [The Oxford IIIT Pet Dataset](https://www.kaggle.com/devdgohil/the-oxfordiiit-pet-dataset)\n",
        "\n",
        "### Disclaimer:\n",
        "**This is just to implement the core concept of basic object localization and is not to be taken serious - this is just experimental and to learn it before going to object detection**\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9samIqgWbqHj"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "import numpy as np\n",
        "import csv\n",
        "import cv2\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt1cIZKG3SNX"
      },
      "source": [
        "os.mkdir('data') \n",
        "\n",
        "with zipfile.ZipFile(\"drive/MyDrive/AI/Data/ImageData/oxford_iiit.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"./data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUxXMMkyX5cb"
      },
      "source": [
        "def pad_image(img, IMG_SIZE):\n",
        "    image = cv2.copyMakeBorder(img, 0, IMG_SIZE-img.shape[0], 0, IMG_SIZE-img.shape[1], cv2.BORDER_CONSTANT)\n",
        "    return image"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuL3ITTV4BH8",
        "outputId": "01c64691-f1a3-416a-8333-1829d2609213"
      },
      "source": [
        "IMG_SIZE = 550\n",
        "XMLS = \"./data/annotations/annotations/xmls\"\n",
        "\n",
        "training_data = []\n",
        "xml_files = glob.glob(\"{}/*xml\".format(XMLS))\n",
        "for i, xml_file in enumerate(xml_files):\n",
        "    tree = ET.parse(xml_file)\n",
        "\n",
        "    path = os.path.join('./data/images/images', tree.findtext(\"./filename\"))\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if img.shape[0] < IMG_SIZE and img.shape[1] < IMG_SIZE:\n",
        "        xmin = int(tree.findtext(\"./object/bndbox/xmin\"))\n",
        "        ymin = int(tree.findtext(\"./object/bndbox/ymin\"))\n",
        "        xmax = int(tree.findtext(\"./object/bndbox/xmax\"))\n",
        "        ymax = int(tree.findtext(\"./object/bndbox/ymax\"))\n",
        "\n",
        "        image = pad_image(img, IMG_SIZE)\n",
        "        training_data.append([np.array(image), [xmin/IMG_SIZE, ymin/IMG_SIZE, xmax/IMG_SIZE, ymax/IMG_SIZE]])\n",
        "\n",
        "print('training_data length: ', len(training_data))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training_data length:  3634\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EAUPCZWuglh"
      },
      "source": [
        "X = torch.Tensor([i[0] for i in training_data]).view(-1, IMG_SIZE, IMG_SIZE)\n",
        "X = X/255.0\n",
        "y = torch.Tensor([i[1] for i in training_data])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erULjdDlneMp",
        "outputId": "63b19af7-6015-45d2-b44e-8b3f49adf296"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, in_channels, n_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=8, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(8),\n",
        "\n",
        "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(8),\n",
        "\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(16*64*64, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(.5),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(.2),\n",
        "            nn.Linear(1024, n_classes),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(-1, 16*64*64)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net(1, 4).to(device)\n",
        "print(model)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Conv2d(8, 8, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (8): ReLU()\n",
            "    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (11): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (12): ReLU()\n",
            "    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=65536, out_features=4096, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.2, inplace=False)\n",
            "    (6): Linear(in_features=1024, out_features=4, bias=True)\n",
            "    (7): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuWFNtGGv9Dg",
        "outputId": "d18547ff-ecb9-423b-9ac1-8b70c05972f4"
      },
      "source": [
        "# to double check dimensions\n",
        "model.conv(X[:1].view(-1, 1, 550, 550).to(device)).size()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 64, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg9ILtQ_1Lcd",
        "outputId": "d37d12a2-9e12-4005-c1c6-544d3a1f2615"
      },
      "source": [
        "BATCH_SIZE = 4\n",
        "EPOCHS = 10\n",
        "model.train()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "def train(model):\n",
        "    for epoch in range(EPOCHS):\n",
        "        for i in tqdm.tqdm(range(0, len(X), BATCH_SIZE)):\n",
        "            batch_X = X[i:i+BATCH_SIZE].view(-1, 1, 550, 550).to(device)\n",
        "            batch_y = y[i:i+BATCH_SIZE].to(device)\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            outputs = model(batch_X)\n",
        "            loss = loss_function(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()    \n",
        "\n",
        "        print(f\"\\nEpoch: {epoch}. Loss: {loss}\")\n",
        "\n",
        "\n",
        "train(model)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 909/909 [00:30<00:00, 29.67it/s]\n",
            "  0%|          | 4/909 [00:00<00:24, 37.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0. Loss: 0.005115551874041557\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 909/909 [00:30<00:00, 29.71it/s]\n",
            "  0%|          | 4/909 [00:00<00:24, 37.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1. Loss: 0.00565384142100811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 909/909 [00:30<00:00, 29.68it/s]\n",
            "  0%|          | 4/909 [00:00<00:24, 37.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 2. Loss: 0.0017478576628491282\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 909/909 [00:30<00:00, 29.74it/s]\n",
            "  0%|          | 4/909 [00:00<00:24, 37.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 3. Loss: 0.00245093647390604\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 909/909 [00:30<00:00, 29.72it/s]\n",
            "  0%|          | 4/909 [00:00<00:24, 37.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 4. Loss: 0.001998061779886484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 909/909 [00:30<00:00, 29.71it/s]\n",
            "  0%|          | 4/909 [00:00<00:24, 37.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 5. Loss: 0.0021302467212080956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 909/909 [00:30<00:00, 29.72it/s]\n",
            "  0%|          | 4/909 [00:00<00:24, 37.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 6. Loss: 0.0025986104737967253\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 909/909 [00:30<00:00, 29.71it/s]\n",
            "  0%|          | 4/909 [00:00<00:24, 37.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 7. Loss: 0.0031612785533070564\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 909/909 [00:30<00:00, 29.70it/s]\n",
            "  0%|          | 4/909 [00:00<00:24, 37.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 8. Loss: 0.0011636980343610048\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 909/909 [00:30<00:00, 29.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 9. Loss: 0.0014444717671722174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTgBvy4CDLmE"
      },
      "source": [
        "e = 1\n",
        "\n",
        "label = model(X[e].view(-1, 1, 550, 550).to(device))\n",
        "\n",
        "xmin = label[0][0].item()\n",
        "ymin = label[0][1].item()\n",
        "xmax = label[0][2].item()\n",
        "ymax = label[0][3].item()\n",
        "\n",
        "img = training_data[e][0]\n",
        "bnd_img = cv2.rectangle(img, (int(xmin*IMG_SIZE), int(ymin*IMG_SIZE)), (int(xmax*IMG_SIZE), int(ymax*IMG_SIZE)), (255, 0, 0), 2)\n",
        "plt.imshow(bnd_img, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}